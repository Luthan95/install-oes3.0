apiVersion: v1
data:
  config.properties: |
    #########################################################################################################
    #                                      Application configuration
    #########################################################################################################

    management.endpoints.web.base-path=/mgmt
    management.endpoint.health.show-details=always
    management.endpoint.health.show-components=always

    kubernetes.prometheus.metric.label=__name__
    kubernetes.prometheus.host.tagname=exported_container_label_io_kubernetes_pod_name
    kubernetes.prometheus.tomcat.host.tagname=container_label_io_kubernetes_pod_name

    aws.prometheus.host.tagname=destination_workload
    aws.prometheus.baseline.host.tagvalue=version2a
    aws.prometheus.canary.host.tagvalue=version2b

    prometheus.metrics.api.path=/api/v1/label/__name__/values
    prometheus.metrics.aggregator=avg
    prometheus.metrics.sampling.value=10
    prometheus.metrics.rate.duration=60s
    #true always taking cluster name, false always taking pod names
    prometheus.cluster.name=false
    isPodFinderEnabled=false

    prometheus.services=apache,haproxy,http,tomcat
    prometheus.configured.service=istio
    stackdriver.services=tomcat
    stackdriver.metrics.template.path=/opt/opsmx/base-templates/stackdriver/tomcat-metrics.json
    elastic.search.services=apache,tomcat
    #datadog.services=tomcat (datadog services are being read from datadog api by truncating the prefix of each metric name
    #custom.service.dropdown.value=Custom service

    # Reading hibernate.cfg.xml from file system
    hibernate.configFilePath=/opt/opsmx/hibernate.cfg.xml

    #aws.prometheus.hostname=

    # Data science micro service configuration parameters
    python.server.protocol=https://
    python.analysis.url=localhost:5005

    # Data Science Microservice Properties
    datascience.workers.count=4
    datascience.server.address=0.0.0.0:5005

    server.protocol=http://
    reporting.server.url=/opsmx-analysis/public/canaryAnalysis.html#/analysis/
    casservice.baseurl=localhost:8090
    metricservice.baseurl=localhost:9090

    elastic.search.metrics.template.path=/opt/opsmx/elasticsearch_template_format.json
    elasticsearch.metrics.sampling.value=10
    elastic.search.query.template.path=/opt/opsmx/elasticsearch_metric_query_template.json
    elastic.search.metrics.index.path=/opt/opsmx/elasticsearch_index_template.json
    elastic.search.kibana.url=http://34.211.233.166:5601/app/kibana#/discover?_g=()&_a=(columns:!(_source),index:METRIC_INDEX,interval:auto,query:(language:lucene,query:''),sort:!('@timestamp',desc))

    # Required details for log analysis
    home.directory=/home/ubuntu/
    logfiles.base.path=/home/ubuntu/logdata/
    logfiles.aca.path=/home/ubuntu/acainputs/
    logfiles.feedback.path=/home/ubuntu/logdata/feedback/
    logfiles.pca.path=/home/ubuntu/ScoringAndPCA/
    java.logs.path=/home/ubuntu/logs/
    k8.logpulling.url=https://api-opsmxcluster-k8s-loca-fsgjhv-1527274479.us-east-2.elb.amazonaws.com/api/v1/namespaces/kube-system/services/elasticsearch-logging/proxy/logstash-*/fluentd/_search
    k8.logpulling.username=admin
    k8.logpulling.password=eX2uNGR55k98mCqobEwUzMIX63Aknm0D
    k8.query.keyword=kubernetes.pod_name.keyword
    k8.config.filepath=/home/ubuntu/.kube/
    elasticsearch.k8.log.query.file.path=/opt/opsmx/base-templates/elasticsearch/elasticsearch_log_query.json
    elasticsearch.log.query.file.path=/opt/opsmx/base-templates/elasticsearch/elasticsearch_log_query.json
    elasticsearch.logpulling.url=/_search?scroll=2m
    dockerswarm.logpulling.scroll.url=/_search/scroll
    dockerswarm.query.file.path=/opt/opsmx/base-templates/elasticsearch/elasticsearch_swarmlog_query.json
    elasticsearch.query.keyword=container_id.keyword
    elasticsearch.response.keywords=message,exception.exception_message,log
    elasticsearch.log.filesize.in.MB=100

    # Sumologic detials

    sumologic.logpulling.url1=https://api.
    sumologic.logpulling.url2=.sumologic.com/api/v1/search/jobs
    sumologic.logpulling.us1=https://api.sumologic.com/api/v1/search/jobs
    sumologic.log.query.file.path=/opt/opsmx/base-templates/sumologic/sumologic_log_query.json
    sumologic.response.keywords=message,exception.exception_message,log
    sumologic.log.filesize.in.MB=100
    sumologic.accessid.keyword=dummyaccessid
    sumologic.accesskey.keyword=dummyaccesskey
    sumologic.zone.keyword=us2
    sumologic.query.keyword=container_id.keyword
    sumologic.query.url=https://service.<zone>.sumologic.com/ui/#/search/@<starttime>,<endtime>@_sourceCategory=<pod>
    sumologic.query.url.us1=https://service.sumologic.com/ui/#/search/@<starttime>,<endtime>@_sourceCategory=<pod>
    sumologic.query.data=/messages?offset=0&limit=10000

    # Stackdriver details
    stackdriver.services=tomcat
    stackdriver.metrics.template.path=/opt/opsmx/base-templates/stackdriver/apm.json
    stackdriver.query.url=https://console.cloud.google.com/logs/#/search/@<logfilter>

    # Kibana details
    kibana.query.url=/app/kibana#/discover?_g=(refreshInterval:(pause:!t,value:0),time:(from:'<starttime>',mode:absolute,to:'<endtime>'))&_a=(columns:!(_source),filters:!(('$state':(store:appState),meta:(alias:!n,disabled:!f,index:'<index>',key:_index,negate:!f,params:(query:'<indexvalue>',type:phrase),type:phrase,value:'<indexvalue>'),query:(match:(_index:(query:'<indexvalue>',type:phrase)))),('$state':(store:appState),meta:(alias:!n,disabled:!f,index:'<index>',key:<scope>,negate:!f,params:!('<scopevalue>'),type:phrases,value:'<scopevalue>'),query:(bool:(minimum_should_match:1,should:!((match_phrase:(<scope>:'<scopevalue>'))))))),index:'<index>',interval:auto,query:(language:lucene,query:''),sort:!('@timestamp',desc))

    kibana.query=/app/kibana#/discover?_g=()&_a=(columns:!(_source),index:<index>,interval:auto,query:(language:lucene,query:''),sort:!('@timestamp',desc))

    elasticsearch.index=logstash-pipeline-*
    log.template=log-template
    metric.template=metric-template
    log.analysis.file=/home/ubuntu/logdata/logAnalysis.py
    canary.analysis.filepath=/home/ubuntu/Python-code/canary/canaryplusversion.py
    log.feedback.analysis.file=/home/ubuntu/logdata/feedbackAnalysis.py
    python.version=python

    # Retry the log query attributes
    totalDurationInMinutes=6
    intervalDurationInSeconds=60

    newrelic.metric.template.filter.params=WebTransaction(.*)GET(.*),WebTransaction(.+)POST(.*),WebTransaction(.+)PUT(.*),WebTransaction(.+)DELETE(.*),WebTransaction(.+)PATCH(.*)
    newrelic.metrics.template.path=/opt/opsmx/base-templates/newrelic/newrelic-apm-rest.json
    #newrelic.metric.template.filter.param=/greeting
    newrelic.group.metric.delimiter=;

    #datadog metric analysis required details
    datadog.metric.tag=host
    datadog.metrics.template.path=/opt/opsmx/base-templates/datadog/
    datadog.infra.metrics.template.path=/opt/opsmx/base-templates/datadog/infra.json
    datadog.timeseries.metricdata.client.url=https://api.datadoghq.com/api/v1/query
    datadog.apm.metrics.template.path=/opt/opsmx/base-templates/datadog/apm.json
    datadog.timeseries.metricdata.host=api.datadoghq.com
    datadog.application.weeks=1

    canary.default.minscore=80
    canary.default.maxscore=90
    metricdata.fetcher.url=http://localhost:9090/metricdata
    monitoring.service.baseurl=http://localhost:9090

    basedata.filepath=/home/ubuntu/BaseData/USER_NAME_PLACE_HOLDER/TEMPLATE_NAME_PLACE_HOLDER/Data
    #time period is in hours
    basedata.time.period=-24
    system.r.path=/usr/bin/Rscript
    weights.computation.filepath=/home/ubuntu/long_term_weights.R

    sonar.metrics.file.path=/opt/opsmx/base-templates/sonar/sonar_metrics.json
    auditEnabled=false

    # timing parameters for analysis retries.
    opsmx.job.refreshMilliseconds=30000
    opsmx.job.timeoutMilliseconds=120000
    opsmx.job.restartJobLimit=5
    opxmx.job.staleCheckMilliseconds=60000

    #Thread limit for calls to analysis servicec
    analysis.threadpool.size=4

    # metric multi service constants
    multiservice.monitoring.service.url=localhost:9090/metricdatapath

    #######################################################################################
    #           Additional configuration that can be changed via values.yaml
    #######################################################################################

    # Data science analysis algorithm, typically spell/perl are specified
    python.algorithm=spell

    # Spinnaker information
    spinnaker.login.admin.enabled=false
    spinnaker.baseurl=http://40.64.77.192:9000/gate/
    spinnaker.login.admin.username=admin
    spinnaker.login.admin.password=OpsMx@123

    # Data source attributes
    spring.datasource.url=jdbc:postgresql://db-opsmx:5432/opsmx
    spring.datasource.username=postgres
    spring.datasource.password=networks123

    # LDAP login attributes
    isLdapAuthEnabled=
    ldap.url=ldap://oes-ldap:3389
    ldap.base.dn=DC=example,DC=com
    ldap.user.filter.pattern=(&(objectclass=person)(cn=USERNAME))
    ldap.admin.user.groups=Administrators

    # Enable Build Analysis
    build.analysis=false


  hibernate.cfg.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <!-- <!DOCTYPE hibernate-configuration PUBLIC "-//Hibernate/Hibernate Configuration
        DTD 3.0//EN" "hibernate-configuration-3.0.dtd"> -->
    <!DOCTYPE hibernate-configuration SYSTEM "classpath:///hibernate-configuration-3.0.dtd">
    <hibernate-configuration>
            <session-factory>
                   <!-- Settings for a database -->
                   <property name="connection.driver_class">org.postgresql.Driver</property>
                   <!--for kubernet service-->
                   <property name="connection.url">jdbc:postgresql://db-opsmx:5432/opsmx</property>
                   <property name="connection.username">postgres</property>
                   <property name="connection.password">networks123</property>

                   <property name="dialect">org.hibernate.dialect.PostgreSQLDialect</property>
                   <property name="hibernate.query.factory_class">org.hibernate.hql.ast.ASTQueryTranslatorFactory</property>
                   <property name="show_sql">false</property>
                   <property name="hbm2ddl.auto">update</property>
                   <!-- <property name="hibernate.cache.use_second_level_cache">true</property>
                   <property name="hibernate.cache.use_query_cache">true</property>
                    --><!-- <property name="hibernate.cache.provider_class">org.hibernate.cache.EhCacheProvider</property>
                   <property name="hibernate.cache.region.factory_class">org.hibernate.cache.ehcache.EhCacheRegionFactory</property>
                   <property name="net.sf.ehcache.configurationResourceName">/hibernate-cache-config.xml</property>
                    --><!-- <property name="hibernate.hbm2ddl.auto">validate</property> -->

                   <!-- Disable second-level cache. -->
                   <!-- <property name="cache.provider_class">org.hibernate.cache.NoCacheProvider</property> -->

                   <property name="hibernate.temp.use_jdbc_metadata_defaults">true</property>

                   <!-- Bind the getCurrentSession() method to the thread. -->
                   <property name="current_session_context_class">thread</property>

                   <!-- hibernate c3p0 connection pooling configuration -->
                   <property name="hibernate.c3p0.acquire_increment">1</property>
                   <property name="hibernate.c3p0.idle_test_period">60</property> <!-- seconds -->
                   <property name="hibernate.c3p0.min_size">1</property>
                   <property name="hibernate.c3p0.max_size">10</property>
                   <property name="hibernate.c3p0.max_statements">0</property>
                   <property name="hibernate.c3p0.timeout">0</property> <!-- seconds -->
                   <property name="hibernate.c3p0.acquireRetryAttempts">10</property>
                   <property name="hibernate.c3p0.acquireRetryDelay">15000</property>
                   <property name="hibernate.c3p0.testConnectionOnCheckout">true</property>
                   <property name="hibernate.c3p0.preferredTestQuery">SELECT 1</property>

                   <mapping resource="model.hbm.xml" />
            </session-factory>
    </hibernate-configuration>


kind: ConfigMap
metadata:
  name: autopilotbackendconfig
